import time
import random
import numpy as np
from deap import base
from deap import creator
from deap import tools
import json

from ml_pentest.file_manipulations.pe_format.api_call_injection import ApiCallInjection
from ml_pentest.attacks.blackbox.genetic_attack.genetic_engine.genetic_algorithm_base import GeneticEngine
from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.gamma_attack import GammaAttack
from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.gamma_result import GammaResult


class GammaAPICallInjection(GammaAttack, GeneticEngine):
    """
    GammaAPICallInjection is a specialized class that extends GammaAttack and GeneticEngine to implement
    the GAMMA attack using API call injection as the manipulation technique.
    See Demetrio et al. (https://ieeexplore.ieee.org/document/9437194).

    Attributes:
        _section_population_length (int): The number of sections that can be injected into the input sample.
        _stagnation (int): The number of iterations without improvement before stopping the attack.
        _input_sample (np.ndarray): The input sample to be attacked.
        _api_list (list): A list of API calls that can be injected.
        _manipulator (ApiCallInjection): An object that performs the API call injection.

    Methods:
        __init__(): Initializes a GammaAPICallInjection object with given parameters.
        initialization(): Initializes the genetic algorithm and evaluates the initial population.
        termination_condition(): Checks if the termination condition has been met.
        iteration(): Performs one iteration of the genetic algorithm.
        _evaluate(): Evaluates the fitness of each individual in the population.
        exiting_operations(): Performs exiting operations and returns a GammaResult object.
        compute_fitness_function(): Computes the fitness function for a given sample and manipulation vector.
        _compute_loss(): Computes the loss function for a given confidence score and penalty value.
        compute_reg_term(): Computes the regularization term for a given sample and adversarial sample.
        compute_confidence(): Computes the confidence score for a given sample.
        run(): Runs the genetic algorithm and returns a GammaResult object.
        get_attack_characteristic(): Returns a JSON string containing all attack characteristics.
    """


    def __init__(self, api_list , model_wrapper , population_size, lambda_value, iterations, input_sample=None, query_budget=None, seed=None, debug=False, hard_label=False, threshold=0.5, loss='l1', stagnation=5):
        """
        Initializes the GammaSectionInjection object with the given parameters.

        Args:
            api_list (list): A list of couples [dll_name, function_name] of each API that can be included during the optimization
            model_wrapper (ModelWrapper): The classifier to be attacked with classification function.
            population_size (int): The size of the population of individuals in the genetic algorithm.
            lambda_value (float): The lambda value used in the fitness function.
            iterations (int): number of maximum iterations of the genetic algorithm. If query_budget is used, the maximum number 
                              of iterations will be limited by the query budget.
            input_sample (np.ndarray): The input sample to be attacked. Default to None, if you want only to initialize the attack object.
            query_budget (int): The maximum number of queries allowed to the classifier. Defaults to None, which means 
                                that there is no limit to the number of queries.
            seed (int): The seed to be used in the random number generator.
            debug (bool): Whether to print debug information.
            hard_label (bool): Whether to use hard labels in the fitness function.
            threshold (float): The threshold used to detect a sample as a malware. Tipically, if the
                               confidence of the classifier is > 0.5, this is a malware, but you can 
                               change the value if this is not the case. This value is used only in hard label mode.
            loss (str): The loss function used in the fitness function to combine confidence and penalty term. With 
                        'l1' the loss is the absolute value of the difference in bytes between original samples and adversarial one. 
                        The other values are:
                        - 'cw', in which the loss is computed as max(confidence - self.threshold + 0.1, 0) + penalty.
                        - 'log', in which the loss is computed as -log(1 - confidence) + penalty.
            stagnation (int): the number of iteration without improvement before stopping the attack. Defaults to 5.
        Returns:
            None
        """
        super().__init__(model_wrapper , population_size,
                         lambda_value, iterations, query_budget, seed, debug, hard_label, threshold, loss)
        # Number of section to inject in the input sample
        self._section_population_length = len(api_list)
        # number of iterations without improvement before stopping
        self._stagnation = stagnation
        self._input_sample = input_sample
        self._api_list = api_list
        self._manipulator = ApiCallInjection(self._input_sample, self._api_list)

    def initialization(self):
        """
        Initializes the genetic algorithm by creating the necessary objects and registering the required functions
        with the DEAP toolbox. It also creates a population of individuals and evaluates their fitness.

        Returns:
            None
        """
        if self._input_sample is None:
            raise ValueError(
                "Input sample is not provided! Use the method set_sample to set it before running attack.")
        self._start_time = time.time()
        if self._debug:
            print("==== Initialization phase ====")
        ################################### INITIALIZE DHE DEAP TOOLBOX ###################################
        # creates a Fitness object that minimizes fitness. The weights argument is used to define the sign of the fitness.
        creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
        # creates an Individual class that is a list of integers with the fitness attribute set to the FitnessMin class
        #  The "Individual" class represents a potential solution to the problem being solved (a candidate solution)
        creator.create("Individual", list, fitness=creator.FitnessMin)
        # Create a toolbox for evolution that contains the evolutionary operators
        toolbox = base.Toolbox()
        #  Register a function that generates a random integer in  [0,1] by using the random.randomint method
        toolbox.register(alias='attr_integer', function=random_integer)
        # Creating an individual with a list of integer attributes (with population_size length) between 0 and 1 and registering
        # it in the toolbox for use in the genetic algorithm. A candidate is represented by a list
        # s = [0 1 0 ...] where s[i]=1 indicate that the i-th section must be ijnected.
        toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_integer,
                         n=self._section_population_length)
        # Create a population of individuals and registering it in the toolbox for use in the genetic algorithm.
        toolbox.register("population", tools.initRepeat,
                         list, toolbox.individual)
        # Function performs one-point crossover on two individuals using the cxOnePoint method
        toolbox.register("crossover", tools.cxOnePoint)
        # Mutate function mutates an individual with a probability of 0.3 using the random_mutation method.
        toolbox.register("mutate", random_mutation, indpb=0.3)
        # Selects the best individuals from a population using the selTournament method
        toolbox.register("select", tools.selTournament,
                         tournsize=self._population_size)
        # saves the toolbox object into the class attribute
        self._toolbox = toolbox

        # The _slice_indexes list is used to slice the population into smaller subpopulations.
        # The single element in the list represents the end index of the first subpopulation,
        # which is equal to the total population size.
        self._slice_indexes = [self._population_size]
        ###############################################################################
        # Creates a population of individuals and evaluates their fitness on the input sample.
        self._population = self._toolbox.population(n=self._population_size)

        # initialize this tuple that contain the best fit and the best candidate actually discovered
        self._best_candidate = (np.infty, None)
        self._evaluate(self._population)
        # CXPB  is the probability with which two individuals are crossed
        self._CXPB = 0.9
        # MUTPB is the probability for mutating an individual
        self._MUTPB = 0.3
        # this is the index of the current iteration
        self._iteration = 0

        # The _last_n_best_fits list is used to keep track of the best fitness values of the last n iterations,
        # where n is the stagnation parameter passed to the constructor of the GammaSectionInjection class.
        # This list is used to check if the algorithm has stagnated, i.e., if the best fitness value has not
        # improved for n iterations.
        self._last_n_best_fits = []

    def termination_condition(self):
        """
        Check if the termination condition has been met.

        Returns:
            bool: True if the termination condition has been met, False otherwise.
        """
        if len(self._last_n_best_fits) == self._stagnation and ( all(
                np.array(self._last_n_best_fits) == np.infty) or
                all((np.array(self._last_n_best_fits) - self._best_fitness) < 1e-6) ):
            if self._debug:
                print('Stagnating result!')
            return True
        if not self._query_budget:
            if self._debug and self._iteration >= self._iterations:
                print("\nTerminating condition met! g:{}, iterations:{}".format(
                    self._iteration, self._iterations))
            return self._iteration >= self._iterations
        if self._debug and ((self._iteration >= self._iterations) or ((self._iteration+1)*self._population_size >= self._query_budget)):
            print("\nTerminating condition met! g:{}, iterations:{}, query budget {}".format(
                self._iteration, self._iterations, self._query_budget))
        return (self._iteration >= self._iterations) or ((self._iteration+1)*self._population_size >= self._query_budget)

    def iteration(self):
        """
        Perform one iteration of the genetic algorithm.

        Returns:
            None
        """
        if self._debug:
            print("\n==== Iteration {} ====".format(self._iteration + 1))
        ############## SELECTION ################
        # Select the next generation individuals
        selected_individuals = self._toolbox.select(
            self._population, self._population_size)
        # Clone the selected individuals
        selected_individuals = list(
            map(self._toolbox.clone, selected_individuals))
        ############## CROSSOVER ################
        # Apply crossover and mutation on the selected individuals
        for child1, child2 in zip(selected_individuals[::2], selected_individuals[1::2]):
            if random.random() < self._CXPB:
                self._toolbox.crossover(child1, child2)
                del child1.fitness.values
                del child2.fitness.values
        ############## MUTATION ################
        for mutant in selected_individuals:
            if random.random() < self._MUTPB:
                self._toolbox.mutate(mutant)
                del mutant.fitness.values

        # Evaluate the individuals with an invalid fitness
        # (i.e. the ones that have been mutated or crossed in the previous step)
        to_evaluate = [
            ind for ind in selected_individuals if not ind.fitness.valid]
        # This line of code appends the length of the to_evaluate list to the _slice_indexes list.
        # This is required because _slice_indexes is used to keep track of the indexes of the individuals
        # in the population that belong to each section.
        # By appending the length of to_evaluate, we are essentially marking the end of the current section and
        # the beginning of the next section in the population. This is important for the selection process,
        # as it ensures that individuals from each section are selected with equal probability.
        self._slice_indexes.append(len(to_evaluate))

        self._evaluate(to_evaluate)

        self._population.extend(to_evaluate)
        # Compute values to determine stagnation condition
        fits = [candidate.fitness.values[0] for candidate in self._population]
        self._best_fitness = min(fits)
        self._last_n_best_fits.insert(0, self._best_fitness)
        self._last_n_best_fits = self._last_n_best_fits[:self._stagnation]

        if self._debug:
            print(f'>{self._iteration} - Global min: {self._best_fitness}')
        self._iteration += 1

    def _evaluate(self, to_evaluate):
        """
        Evaluates the fitness of each individual in the population by computing the fitness function for each individual.

        Parameters
        ----------
        to_evaluate : list
            A list of individuals to evaluate.

        Returns
        -------
        None
        """
        if not self._model_wrapper._use_batch:            
            fitness = []
            for candidate in to_evaluate:
                fit_value, adv_sample = self.compute_fitness_function(self._input_sample, np.array(candidate))
                fitness.append([fit_value])
                if fit_value < self._best_candidate[0]:
                    self._best_candidate = (fit_value, adv_sample)
                
        else:
            adv_samples = []
            reg_terms = []
            for manipulation_vector in to_evaluate:
                self._manipulator.set_pe_file(self._input_sample)
                adv_sample = self._manipulator.apply_manipulation(manipulation_vector)
                adv_samples.append(bytes(adv_sample))
                reg_terms.append(self.compute_reg_term(manipulation_vector=manipulation_vector, section_population=self._api_list))
            confidences = self._model_wrapper.classify_batch(adv_samples)
            fitness = []
            for i in range(len(to_evaluate)):
                fitness.append([self._compute_loss(confidences[i], reg_terms[i])])
        
        if self._debug:
            print("Fitness values: {}".format(fitness))
        for candidate, fit in zip(to_evaluate, fitness):
            candidate.fitness.values = fit
                
            

    def exiting_operations(self):
        """
        Performs the exiting operations of the genetic algorithm, including selecting the best candidate, applying the
        manipulation to the input sample, and returning a GammaResult object with the manipulated sample and other
        relevant information.

        Returns
        -------
        GammaResult
            A GammaResult object containing the manipulated sample and other relevant information.
        """
        del creator.FitnessMin
        del creator.Individual
        adv_sample = self._best_candidate[1]
        if self._debug:
            print("Best fit: ", self._best_candidate[0])
            if adv_sample is not None:
                print("Confidence: ", self.compute_confidence(bytes(adv_sample)))
        return GammaResult(adv_sample, time.time() - self._start_time, self._iteration, (self._iteration+1) * self._population_size, len(self._last_n_best_fits) == self._stagnation and (
            all(np.array(self._last_n_best_fits) == np.infty) or all((np.array(self._last_n_best_fits) - self._best_fitness) < 1e-6) ))

    def compute_fitness_function(self, sample, manipulation_vector):
        """
        Computes the fitness function for a given sample and manipulation vector. The fitness function is defined as the
        sum of the classification score and the regularization term.

        Parameters
        ----------
        sample : numpy.ndarray
            The array that represent the file to evaluate as byte arrays.
        manipulation_vector : list
            A list of floats representing the manipulation vector.

        Returns
        -------
        float
            The value of the fitness function.
        """
        self._manipulator.set_pe_file(sample)
        adv_sample = self._manipulator.apply_manipulation(manipulation_vector)
        return self._compute_loss(self.compute_confidence(bytes(adv_sample)), self.compute_reg_term(sample, adv_sample)), adv_sample

    def _compute_loss(self, confidence, penalty):
        """
        Computes the loss function for a given confidence score and penalty value. The loss function is defined based on
        the chosen loss type, which can be 'l1', 'cw', or 'log'.

        Parameters
        ----------
        confidence : float
            The confidence score of the classification function.
        penalty : float
            The penalty value to be added to the loss function.

        Returns
        -------
        float
            The value of the loss function.
        """
        if self._loss == 'l1':
            return confidence + penalty
        if self._loss == 'cw':
            return max(confidence - self._threshold + 0.1, 0) + penalty
        if self._loss == 'log':
            return -np.log(1.0001 - confidence) + penalty
        raise ValueError('NO LOSS')

    def compute_reg_term(self, sample, adv_sample):
        """Compute the regularization term for the given sample and adversarial sample.

        Args:
            sample (np.ndarray): a numpy array of integers that represent the input sample.
            adv_sample (np.ndarray, list): a numpy array of integers that represent the adversarial sample.

        Returns:
            int : the number of injected bytes into the adversarial sample
        """
        sample = np.array(sample).tolist()
        adv_sample = np.array(adv_sample).tolist()
        import lief, os
        sample: lief.PE.Binary = lief.PE.parse(raw=sample)
        adv_sample: lief.PE.Binary = lief.PE.parse(raw=adv_sample)
        builder_sample = lief.PE.Builder(sample)
        builder_adv_sample = lief.PE.Builder(adv_sample)
        builder_sample.build_imports(True).patch_imports(True)
        builder_adv_sample.build_imports(True).patch_imports(True)
        builder_sample.build()
        builder_adv_sample.build()

        return self._lambda * (len(builder_adv_sample.get_build()) - len(builder_sample.get_build()))

    def compute_confidence(self, sample):
        """Compute f(sample), where f is the classification function"""
        confidence = self._model_wrapper.classify_sample(sample)
        #print("Confidence: ", confidence)
        if self._hard_label:
            return np.infty if confidence > self._threshold else 0
        return confidence

    def run(self):
        """
        Runs the genetic algorithm by performing initialization, iterations, and exiting operations until the termination
        condition is met. Returns the result of the exiting operations and sets the elapsed time attribute.

        :return: The result of the exiting operations and the elapsed time.
        """
        self.initialization()
        while not self.termination_condition():
            self.iteration()
        result = self.exiting_operations()
        return result
    
    def get_attack_characteristic(self):
        """Return a string with all attacks characteristics in JSON format.
        """
        attack_characteristics = {
            "attack": self.__class__.__name__,
            "population_size": self._population_size,
            "lambda": self._lambda,
            "max_iterations": self._iterations,
            "query_budget": self._query_budget,
            "seed": self._seed,
            "hard_label": self._hard_label,
            "threshold": self._threshold,
            "loss": self._loss,
            "stagnation": self._stagnation,
            "section_population_length": self._section_population_length
            }
        return json.dumps(attack_characteristics)


def random_mutation(individual, indpb):
    """
    Apply the mutation operator, that perturb randomly each entry of the individual, with a given probability.
    The mutation is applied in-place.

    Parameters
    ----------
    individual :
            the individual to mutate
    indpb : float
            the probability of altering a single entry
    Returns
    -------
    tuple
            the mutated individual, the mutatio is in-place
    """
    size = len(individual)
    for i in range(size):
        if random.random() < indpb:
            individual[i] = 0 if individual[i] == 1 else 0
    return individual

def random_integer():
    return random.randint(0, 1)

